# Sample script on how to parse SEEL logs generated by "SEEL_gateway_node.ino"

# This script assumes NODEs are run uninterrupted. If NODES are unplugged, paused, and then re-plugged,
# the script will state that NODE missed BCASTS during the duration of the pause. Quick power cycles are okay. 
# If node join entries are not captured in the logs (logging created on an established network), node IDs can be added in the "Hardcoded Section"

# Tested with Python 3.5.2

# Requires installation of sklearn: "pip3 install sklearn"

# To run: python3 <path_to_this_file>/SEEL_log_parser.py <path_to_data_file>/<data_file> (optional)<path to param file>/<param file>

# Expected input format (All <> is 1 byte):
# Broadcast time: "BT: <time>"
# Broadcast data: "BD: <INDEX BCAST 0> <INDEX BCAST 1> ....
# Node data: <INDEX DATA 0> <INDEX DATA 1> ....

# Make sure the "Indexes Section" in this script matches that in "SEEL_Defines.h" and "SEEL_sensor_node.ino"

# Use the deployment info file argument to override default parser parameters. See the "External Variables Section" for more info.

import os
import sys
import math
import importlib
import numpy as np
from sklearn.metrics import r2_score
import matplotlib.pyplot as plt
import networkx as nx
import statistics

class Parameters:
############################################################################
    # General Parameters
    PRINT_ALL_MSGS = False

    PLOT_DISPLAY = False
    
    # Per node plots
    PLOT_NODE_SPECIFIC_BCASTS = False
    PLOT_NODE_SPECIFIC_CONNECTIONS = False
    PLOT_NODE_SPECIFIC_MAPS = False
    
    PLOT_RSSI_ANALYSIS = False
    PLOT_LOCS_WEIGHT_SCALAR = 1000 # Smaller for thicker lines
    PLOT_LOCS_WEIGHT_SCALAR_SPECIFIC = 500 # Smaller for thicker lines

    PARAM_COUNT_WRAP_SAFETY = 10 # Send count will not have wrapped within this many counts, keep it lower to account for node restarts too

############################################################################
    # Hardcode Section
    HC_NJ_ACTUAL_ID_IDX = 0
    HC_NJ_ASSIGNED_ID_IDX = 1
    HC_NJ_CYCLE_JOIN_IDX = 2
    HARDCODED_NODE_JOINS = [
        # Format -> [actual ID, assigned ID, cycle join]
    ]

    HARDCODED_NODE_LOCS = {
        # Format -> node ID: (loc_x, loc_y)
    }
    
    # Node TDMA slots
    HARDCODED_NODE_TDMA = {
        # Format -> node ID: TDMA slot
    }
    
    # Excludes nodes from correlation plots
    # Useful for any outliers that may skew regressions
    HARDCODED_PLOT_EXCLUDE = {
        # Format -> node_id
    }
    
    NETWORK_DRAW_OPTIONS = {
        "node_font_size": 10,
        "node_size": 250,
        "node_color": "white",
        "node_edge_color": "black",
        "node_width": 1,
        "edge_width": 1,
    }

############################################################################
    # Indexes Section
    INDEX_HEADER = 0
    # INDEX_BT 0 used for the text "BT:"
    INDEX_BT_TIME = 1
    # INDEX_BD 0 used for the text "BD:"
    INDEX_BD_FIRST = 1
    INDEX_BD_BCAST_COUNT = 2
    INDEX_BD_SYS_TIME_0 = 3
    INDEX_BD_SYS_TIME_1 = 4
    INDEX_BD_SYS_TIME_2 = 5
    INDEX_BD_SYS_TIME_3 = 6
    INDEX_BD_SNODE_AWAKE_TIME_0 = 7
    INDEX_BD_SNODE_AWAKE_TIME_1 = 8
    INDEX_BD_SNODE_AWAKE_TIME_2 = 9
    INDEX_BD_SNODE_AWAKE_TIME_3 = 10
    INDEX_BD_SNODE_SLEEP_TIME_0 = 11
    INDEX_BD_SNODE_SLEEP_TIME_1 = 12
    INDEX_BD_SNODE_SLEEP_TIME_2 = 13
    INDEX_BD_SNODE_SLEEP_TIME_3 = 14
    INDEX_BD_PATH_HC = 15
    INDEX_BD_PATH_RSSI = 16
    INDEX_BD_SNODE_JOIN_ID = 17 # Repeated
    INDEX_BD_SNODE_JOIN_RESPONSE = 18 # Repeated

    INDEX_DATA_ORIGINAL_ID = 0
    INDEX_DATA_ASSIGNED_ID = 1
    INDEX_DATA_PARENT_ID = 2
    INDEX_DATA_PARENT_RSSI = 3
    INDEX_DATA_BCAST_COUNT = 4
    INDEX_DATA_WTB_0 = 5
    INDEX_DATA_WTB_1 = 6
    INDEX_DATA_WTB_2 = 7
    INDEX_DATA_WTB_3 = 8
    INDEX_DATA_SEND_COUNT_0 = 9
    INDEX_DATA_SEND_COUNT_1 = 10
    INDEX_DATA_PREV_DATA_TRANS = 11
    INDEX_DATA_MISSED_BCASTS = 12
    INDEX_DATA_MAX_QUEUE_SIZE = 13
    INDEX_DATA_CRC_FAILS = 14
    INDEX_DATA_FLAGS = 15

############################################################################
# Default Parameters

parameters = Parameters()

############################################################################
# External Parameters

# Pull in overriding parameters from cmd line argument
# Pass in path to a file as the 2nd argument to this script
# File must have a "Parameters" class similar to the one in this script
# See the example file format in "misc/deployment_info/deployment_info.py"
# Format: python3 <path_to_this_file>/SEEL_log_parser.py <path_to_data_file>/<data_file> (optional)<path to param file>/<param file>

if len(sys.argv) > 2:
    sys.path.insert(1, os.path.dirname(sys.argv[2]))
    extern_file = __import__(os.path.basename(os.path.splitext(sys.argv[2])[0])) 
    Parameters_Mixed = type("Parameters_Mixed", (extern_file.Parameters, Parameters), {})
    parameters = Parameters_Mixed()

############################################################################
# Global Variables

bcast_times = []
bcast_info = []
bcast_info_overflow = {}
bcast_instances = {} # per node, since nodes may join at different times

node_mapping = {}
node_assignments = []
data_info = []

node_analysis = {} # per node
msg_analysis = {} # per node

############################################################################

class Parent:
    def __init__(self, id, rssi):
        self.id = id
        self.rssi = rssi
     
class Cycle_Stats:
    def __init__(self):
        self.parent_rssi = 0
        self.crc_fails = -1
        self.data_transmissions = -1

class Bcast_Info:
    def __init__(self, bcast_num, bcast_inst, sys_time, awk_time, slp_time):
        self.bcast_num = bcast_num
        self.bcast_inst = bcast_inst
        self.sys_time = sys_time
        self.awk_time = awk_time
        self.slp_time = slp_time

    def __str__(self):
        return "Bcast num: " + str(self.bcast_num) + " Inst: " + str(self.bcast_inst) + " System time: " + str(self.sys_time) + " Awake time: " + str(self.awk_time) + " Sleep time: " + str(self.slp_time)
    
class Data_Info:
    def __init__(self, bcast_num, bcast_inst, wtb, prev_data_trans, node_id, parent_id, parent_rssi, send_count, prev_max_queue_size, prev_missed_bcasts, prev_crc_fails, prev_flags):
        self.bcast_num = bcast_num
        self.bcast_inst = bcast_inst
        self.wtb = wtb
        self.node_id = node_id
        self.parent_id = parent_id
        self.parent_rssi = parent_rssi
        self.send_count = send_count
        self.prev_data_trans = prev_data_trans
        self.prev_max_queue_size = prev_max_queue_size
        self.prev_missed_bcasts = prev_missed_bcasts
        self.prev_crc_fails = prev_crc_fails
        self.prev_flags = prev_flags

    def __str__(self):
        return "Bcast num: " + str(self.bcast_num) + "\tBcast inst: " + str(self.bcast_inst) + "\tNode ID: " + str(self.node_id) + \
        "\tParent ID: " + str(self.parent_id) + "\tSend Count: " + str(self.send_count) + "\tParent RSSI: " + str(self.parent_rssi) + \
        "\tPrev Transmissions: " + str(self.prev_data_trans) + "\tWTB: " + str(self.wtb) + "\tPrev Max Q Size: " + str(self.prev_max_queue_size) + \
        "\tMissed Bcasts: " + str(self.prev_missed_bcasts) + "\tPrev CRC Fails: " + str(self.prev_crc_fails) + "\tPrev Flags: " + str( "{:08b}".format(self.prev_flags))

class Node_Analysis: # Per node
    def __init__(self):
        self.node_id = 0
        self.connections = {}
        self.connection_total = 0  
        self.paths = []
        self.cycle_children = {} # per cycle, 0 padded if no data. Index by bcast_inst and then bcast_num
        self.cycle_hops = {} # per cycle, 0 padded if no data. Index by bcast_inst and then bcast_num
        self.children_counts = {}
        self.children_rssi = {}
        self.hops = []
        self.hc_mean = 0
        self.children_mean = 0
        self.cycles = 0 # cycles alive for
        self.data_transmissions = []
        self.avg_data_transmissions = 0
        self.crc_fails = []
        self.avg_crc_fails = 0
        self.max_queue_sizes = []
        self.avg_max_queue_sizes = 0 # Max queue size avg'd across all received messages
        self.rssi = []
        self.avg_rssi = 0
        self.highest_parent_ratio = 0 # Highest connection parent ratio [0, 1]
        self.avg_wtb = 0

class Msg_Analysis: # Per node
    def __init__(self):
        self.node_id = 0
        self.cycle_stats = {} # per bcast inst, per bcast cycle

def node_entry(actual_id, assigned_id, bcast_join):
    print("join id: " + str(actual_id) + "\tresponse: " + str(assigned_id) + "\tB. Join: " + str(bcast_join))
    if assigned_id in node_mapping:
        print("WARNING: Assigned ID " + str(assigned_id) + " is assigned to multiple SNODEs")
    node_mapping[assigned_id] = actual_id
    if node_assignments.count(actual_id) == 0:
        node_assignments.append(actual_id)
        data_info.append([])
        bcast_instances[actual_id] = bcast_join

def search_paths(b_ind, b_num, node_analysis, paths, search_stack, hcount):        
    search_val = search_stack[-1]
        
    # DFS for path append
    for p in paths:
        if paths[p].id == search_val:
            search_stack.append(p)
            hcount += 1
            node_analysis[p].paths.append(search_stack[:])
            node_analysis[p].hops.append(hcount)
            if not b_ind in node_analysis[p].cycle_hops:
                node_analysis[p].cycle_hops[b_ind] = {}
            node_analysis[p].cycle_hops[b_ind][b_num] = hcount
            search_paths(b_ind, b_num, node_analysis, paths, search_stack, hcount)
            hcount -= 1
            search_stack.pop()

def plot_w_lin_reg(x_ax, y_ax, title, x_label, y_label, regression=True, a=1):
        plt.scatter(x_ax, y_ax, alpha=a)
        if regression:
            lin_reg_model = np.polyfit(x_ax, y_ax, deg=1)
            xseq = np.linspace(min(x_ax), max(x_ax), num=100)
            plt.plot(xseq, lin_reg_model[1] + lin_reg_model[0] * xseq)
            model_predict = np.poly1d(lin_reg_model)
            r2 = r2_score(y_ax, model_predict(x_ax))
            plt.title(title + ", R^2=" + str(r2))
        else:
            plt.title(title)
        plt.xlabel(x_label)
        plt.ylabel(y_label)
        plt.show()

def main():
    if len(sys.argv) <= 1:
        print("Unspecified data file")
        exit()
    df_name = sys.argv[1]        

    #if len(sys.argv) > 2:
        #print(sys.argv[2])
        #info_module = __import__(sys.argv[2])
        #print(info_module)

    df = open(df_name)
    df_read = df.readlines()
    df_length = len(df_read)

    if len(parameters.HARDCODED_NODE_JOINS) > 0:
        print("Using HARDCODED Node Joins")
        for i in parameters.HARDCODED_NODE_JOINS:
            node_entry(i[parameters.HC_NJ_ACTUAL_ID_IDX], i[parameters.HC_NJ_ASSIGNED_ID_IDX], i[parameters.HC_NJ_CYCLE_JOIN_IDX]);

    if len(parameters.HARDCODED_NODE_LOCS) > 0:
        print("Using HARDCODED Node Locs")
        # Uncomment and use for location normalization
        #for i in HARDCODED_NODE_LOCS:
            #print("[" + str(i) + ", " + str(round(HARDCODED_NODE_LOCS[i][0] - <NORM_X>, 7)) + ", " + str(round(HARDCODED_NODE_LOCS[i][1] - <NORM_Y>, 7)) + "]")

    if len(parameters.HARDCODED_PLOT_EXCLUDE) > 0:
        print("Using HARDCODED Plot Excludes")

    # Parse Logs
    current_line = 0
    bcast_instance = -1
    while current_line < df_length:
        line = df_read[current_line].split()
        if len(line) == 0:
            current_line += 1
            continue
        line[1:len(line)] = list(map(int, line[1:len(line)]))
        if line[parameters.INDEX_HEADER] == "BT:": # Bcast time
            bcast_times.append(line[parameters.INDEX_BT_TIME])
        elif line[parameters.INDEX_HEADER] == "BD:": # Bcast data
            sys_time = 0
            awk_time = 0
            slp_time = 0
            sys_time += line[parameters.INDEX_BD_SYS_TIME_0] << 24
            sys_time += line[parameters.INDEX_BD_SYS_TIME_1] << 16
            sys_time += line[parameters.INDEX_BD_SYS_TIME_2] << 8
            sys_time += line[parameters.INDEX_BD_SYS_TIME_3]
            awk_time += line[parameters.INDEX_BD_SNODE_AWAKE_TIME_0] << 24
            awk_time += line[parameters.INDEX_BD_SNODE_AWAKE_TIME_1] << 16
            awk_time += line[parameters.INDEX_BD_SNODE_AWAKE_TIME_2] << 8
            awk_time += line[parameters.INDEX_BD_SNODE_AWAKE_TIME_3]
            slp_time += line[parameters.INDEX_BD_SNODE_SLEEP_TIME_0] << 24
            slp_time += line[parameters.INDEX_BD_SNODE_SLEEP_TIME_1] << 16
            slp_time += line[parameters.INDEX_BD_SNODE_SLEEP_TIME_2] << 8
            slp_time += line[parameters.INDEX_BD_SNODE_SLEEP_TIME_3]
            if line[parameters.INDEX_BD_FIRST] > 0:
                bcast_instance += 1
            bcast_info.append(Bcast_Info(line[parameters.INDEX_BD_BCAST_COUNT], bcast_instance, sys_time, awk_time, slp_time))

            for i in range(math.floor((len(line) - parameters.INDEX_BD_SNODE_JOIN_ID) / 2)):
                repeat_index = i * 2
                join_id = line[parameters.INDEX_BD_SNODE_JOIN_ID + repeat_index]
                if join_id != 0:
                    response = line[parameters.INDEX_BD_SNODE_JOIN_RESPONSE + repeat_index]
                    if response != 0: # Reponse of 0 means error
                        node_entry(join_id, response, len(bcast_times))
        else: # Node Data
            wtb = 0
            send_count = 0
            wtb += line[parameters.INDEX_DATA_WTB_0] << 24
            wtb += line[parameters.INDEX_DATA_WTB_1] << 16
            wtb += line[parameters.INDEX_DATA_WTB_2] << 8
            wtb += line[parameters.INDEX_DATA_WTB_3]
            send_count += line[parameters.INDEX_DATA_SEND_COUNT_0] << 8
            send_count += line[parameters.INDEX_DATA_SEND_COUNT_1]
            if line[parameters.INDEX_DATA_ASSIGNED_ID] in node_mapping:
                original_node_id = node_mapping[line[parameters.INDEX_DATA_ASSIGNED_ID]]
                data_info[node_assignments.index(original_node_id)].append(Data_Info(line[parameters.INDEX_DATA_BCAST_COUNT], bcast_instance, wtb, line[parameters.INDEX_DATA_PREV_DATA_TRANS], original_node_id, line[parameters.INDEX_DATA_PARENT_ID], line[parameters.INDEX_DATA_PARENT_RSSI] - 256, send_count, line[parameters.INDEX_DATA_MAX_QUEUE_SIZE], line[parameters.INDEX_DATA_MISSED_BCASTS], line[parameters.INDEX_DATA_CRC_FAILS], line[parameters.INDEX_DATA_FLAGS]))
        current_line += 1

    # Analysis vars
    total_bcasts = len(bcast_times)
    node_assignments.append(0) # For gateway
    node_mapping[0] = 0
    message_paths = {}
    
    # Plotting vars
    if parameters.PLOT_DISPLAY:
        if len(parameters.HARDCODED_NODE_LOCS) > 0:
            G = nx.DiGraph()
        if parameters.PLOT_RSSI_ANALYSIS:
            analysis_rssi = []
            analysis_transmissions = []

    # GNODE 
    print("Total Bcasts: " + str(total_bcasts))

    # SNODE
    for i in range(len(data_info)):
        node_data_msgs = data_info[i]
        print("********************************************************")
        print("Node " + str(node_assignments[i]))
        if not node_data_msgs: # Empty
            print("No messages received")
            continue
        duplicate_msg_tracker = {}
        wtb = []
        node_id = node_data_msgs[0].node_id
        num_node_msgs = len(node_data_msgs)
        total_data_transmissions = 0
        total_parent_rssi = 0
        total_rssi_counts = 0
        send_count_tracker = 0
        dropped_packets = 0
        dropped_packet_tracker = []
        duplicate_msg = 0
        connection_count = 0 # How many unique (bcast) data msgs we received
        connection_count_max = 0 # Max number of unique bcasts based on highest bcast count per bcast instance
        connection_count_overflow = 0 # Handles 256 overflow in a bcast instance
        connection_count_last_overflow = 0 # Enforces overflow rates so single late msg cannot cause another overflow
        connection_inst_set = set() # Tracks current bcast number per bcast instance, make set to remove dups
        connection_inst_max = 0 # Tracks current max bcast number per bcast instance
        connections = [0] * len(node_assignments)
        connections_rssi = [0] * len(node_assignments)
        queue_size_counter = 0
        max_queue_size = 0
        total_missed_bcasts = {}
        total_crc_fails = 0
        first_wtb = True
        prev_bcast_num = -1
        prev_bcast_inst = -1
        total_bcasts_for_node = total_bcasts - bcast_instances[node_id] + 1

        # Analysis
        node_analysis[node_id] = Node_Analysis()
        node_analysis[node_id].node_id = node_id
        msg_analysis[node_id] = Msg_Analysis()
        msg_analysis[node_id].node_id = node_id

        # Plotting
        plot_snode_bcast_nums = []
        plot_snode_bcast_insts = []
        plot_snode_bcast_used = []

        if parameters.PLOT_RSSI_ANALYSIS:
            analysis_reset = True # Resets on first time or missed bcasts
            analysis_prev_data = [0, 0, 0]

        for msg in node_data_msgs:
            dup = True

            # Figure out how many messages we received from the SNODE versus how many we possibly could have received
            if msg.bcast_inst != prev_bcast_inst:
                if prev_bcast_inst >= 0:
                    connection_inst_max -= (0 if first_bcast_num < 0 else first_bcast_num) # Check if bcast num didn't start at 0 in this inst
                    print("Received messages in bcast instance: " + str(len(connection_inst_set)) + "/" + str(connection_inst_max), str(0 if connection_inst_max == 0 else len(connection_inst_set) / connection_inst_max))        
                    connection_count += len(connection_inst_set)
                    connection_count_max += connection_inst_max
                prev_bcast_inst = msg.bcast_inst
                connection_count_overflow = 0
                connection_count_last_overflow = 0
                connection_inst_set = set()
                connection_inst_max = 0
                prev_bcast_num = -1
                first_bcast_num = -1

            if (len(connection_inst_set) > parameters.PARAM_COUNT_WRAP_SAFETY or msg.bcast_num < (parameters.PARAM_COUNT_WRAP_SAFETY if len(connection_inst_set) == 0 else max(            connection_inst_set)+ parameters.PARAM_COUNT_WRAP_SAFETY)): # Not from previous bcast inst
                if msg.bcast_num < prev_bcast_num and prev_bcast_num > 192 and msg.bcast_num < 64 and len(connection_inst_set) > (connection_count_last_overflow + parameters.PARAM_COUNT_WRAP_SAFETY): # Assume bcast num overflowed, values used are 3/4 of 256 and 1/4 of 256
                    #print("Debug: overflow")
                    connection_count_overflow += 256
                    connection_count_last_overflow = len(connection_inst_set)
                
                overflow_comp_bcast_num = msg.bcast_num + connection_count_overflow
                # Message from non-overflow case came late
                if msg.bcast_num > (255 - parameters.PARAM_COUNT_WRAP_SAFETY) and (len(connection_inst_set) - connection_count_last_overflow) < parameters.PARAM_COUNT_WRAP_SAFETY:
                    overflow_comp_bcast_num -= 256;
                
                if not overflow_comp_bcast_num in connection_inst_set: # Dup check
                    #print("DEBUG: add " + str(overflow_comp_bcast_num))
                    connection_inst_set.add(overflow_comp_bcast_num)
                    if overflow_comp_bcast_num > connection_inst_max:
                        connection_inst_max = overflow_comp_bcast_num
                    if first_bcast_num < 0:
                        first_bcast_num = max(msg.bcast_num - 1, 0)
                    prev_bcast_num = msg.bcast_num
                    plot_snode_bcast_nums.append(msg.bcast_num)
                    plot_snode_bcast_insts.append(msg.bcast_inst)
                    plot_snode_bcast_used.append(False)
                    dup = False
                    if parameters.PRINT_ALL_MSGS:
                        print(str(msg)) 
                #else:
                    #print("Debug: dup")
            #else:
                #print(str(msg)) 
                #print("Debug: ignore")

            if not dup:
                if not msg.bcast_inst in bcast_info_overflow:
                    bcast_info_overflow[msg.bcast_inst] = overflow_comp_bcast_num
                else:
                    bcast_info_overflow[msg.bcast_inst] = (overflow_comp_bcast_num if overflow_comp_bcast_num > bcast_info_overflow[msg.bcast_inst] else bcast_info_overflow[msg.bcast_inst]) # Insert largest bcast_info_overflow value for a bcast_inst
            
                # remove previously missed packet if the packet came in late
                if dropped_packet_tracker.count(msg.send_count) > 0:
                    dropped_packet_tracker.remove(msg.send_count)
                    dropped_packets -= 1

                for i in range(send_count_tracker + 1, msg.send_count):
                    dropped_packets += 1
                    if dropped_packet_tracker.count(i) == 0:
                        dropped_packet_tracker.append(i)
                send_count_tracker = msg.send_count

                # Ignore first WTB during analysis since not system sync'd yet
                if not first_wtb:
                    wtb.append(msg.wtb)
                else:
                    first_wtb = False

                # Not all sent msgs are received, "prev_data_trans" indicates how many total data transmissions 
                # were done by the node in the previous cycle. Duplicates within a cycle can exist

                total_data_transmissions += msg.prev_data_trans
                total_crc_fails += msg.prev_crc_fails

                if msg.parent_rssi != -256: # Impossible value, used to flag RSSI unavailable
                    total_parent_rssi += msg.parent_rssi
                    
                if msg.parent_id in node_mapping:
                    connections[node_assignments.index(node_mapping[msg.parent_id])] += 1
                    connections_rssi[node_assignments.index(node_mapping[msg.parent_id])] += msg.parent_rssi
                    # Create a structure that contains all the paths in the network per bcast num separated by bcast inst
                    if not msg.bcast_inst in message_paths:
                        message_paths[msg.bcast_inst] = {}
                    if not overflow_comp_bcast_num in message_paths[msg.bcast_inst]:
                        message_paths[msg.bcast_inst][overflow_comp_bcast_num] = {}
                    message_paths[msg.bcast_inst][overflow_comp_bcast_num][msg.node_id] = Parent(node_mapping[msg.parent_id], msg.parent_rssi)

                queue_size_counter += msg.prev_max_queue_size
                if msg.prev_max_queue_size > max_queue_size:
                    max_queue_size = msg.prev_max_queue_size

                if msg.prev_missed_bcasts in total_missed_bcasts:
                    total_missed_bcasts[msg.prev_missed_bcasts] += 1
                else:
                    total_missed_bcasts[msg.prev_missed_bcasts] = 1
        
                node_analysis[node_id].data_transmissions.append(msg.prev_data_trans)
                node_analysis[node_id].crc_fails.append(msg.prev_crc_fails)
                node_analysis[node_id].max_queue_sizes.append(msg.prev_max_queue_size)
                node_analysis[node_id].rssi.append(msg.parent_rssi)
        
                if not msg.bcast_inst in msg_analysis[node_id].cycle_stats:
                    msg_analysis[node_id].cycle_stats[msg.bcast_inst] = {}
                if not msg.bcast_num in msg_analysis[node_id].cycle_stats[msg.bcast_inst]:
                    msg_analysis[node_id].cycle_stats[msg.bcast_inst][msg.bcast_num] = Cycle_Stats()
                msg_analysis[node_id].cycle_stats[msg.bcast_inst][msg.bcast_num].parent_rssi = msg.parent_rssi
                # Prev cycle msgs
                if not (msg.bcast_num - 1) in msg_analysis[node_id].cycle_stats[msg.bcast_inst]:
                    msg_analysis[node_id].cycle_stats[msg.bcast_inst][msg.bcast_num - 1] = Cycle_Stats()
                msg_analysis[node_id].cycle_stats[msg.bcast_inst][msg.bcast_num - 1].data_transmissions = msg.prev_data_trans
                msg_analysis[node_id].cycle_stats[msg.bcast_inst][msg.bcast_num - 1].crc_fails = msg.prev_crc_fails

                if parameters.PLOT_RSSI_ANALYSIS:
                    # Compare against queue size 0 because otherwise we don't know how many msgs we got this cycle
                    if analysis_reset or msg.prev_data_trans == 0 or msg.max_queue_size != 0 or msg.parent_id != 0 or msg.bcast_num != (analysis_prev_data[0] + 1):
                        analysis_prev_data = [msg.bcast_num, msg.parent_rssi, msg.max_queue_size]
                        analysis_reset = False
                    else:
                        tpm = msg.prev_data_trans / (analysis_prev_data[2] - msg.max_queue_size + 1); # Average transmissions per msg

                        analysis_rssi.append(analysis_prev_data[1]);
                        analysis_transmissions.append(tpm);

                        analysis_prev_data = [msg.bcast_num, msg.parent_rssi, msg.max_queue_size]
                        analysis_reset = False
            else: # if dup
                duplicate_msg += 1
        
        connection_inst_max -= (0 if first_bcast_num < 0 else first_bcast_num) 
        print("Received messages in bcast instance: " + str(len(connection_inst_set)) + "/" + str(connection_inst_max), str(0 if connection_inst_max == 0 else 
        len(connection_inst_set) / connection_inst_max))
        node_analysis[node_id].cycles = connection_count_max + len(connection_inst_set)
        print("Estimated node lifetime (cycles): " + str(node_analysis[node_id].cycles))
        connection_count += len(connection_inst_set)
        connection_count_max += connection_inst_max
        
        # Store and Print Analysis
        print("\tJoined Network on Bcast: " + str(bcast_instances[node_id]))
        print("\tTotal Received Messages: " + str(num_node_msgs))
        print("\tDuplicate Messages: " + str(duplicate_msg))
        print("\tDropped Packets: " + str(connection_count_max - connection_count))
        print("\tReceived (Total) Percentage: " + str(connection_count / total_bcasts_for_node)) # Total number of GNODE Bcasts received
        node_analysis[node_id].PDR = (0 if connection_count_max == 0 else connection_count / connection_count_max) # Total given times connected (until disconnect or death). This metric is a better representation of PDR
        print("\tReceived (Possible) Percentage: " + str(node_analysis[node_id].PDR))
        if len(wtb) > 0:
            node_analysis[node_id].avg_wtb = statistics.mean(wtb)
            print("\tMean WTB: " + str(node_analysis[node_id].avg_wtb))
            print("\tMedian WTB: " + str(statistics.median(wtb)))
            print("\tStd Dev. WTB: " + str(statistics.stdev(wtb)))
        node_analysis[node_id].avg_data_transmissions = statistics.mean(node_analysis[node_id].data_transmissions)
        print("\tAvg data Transmissions per delivered msg: " + str(node_analysis[node_id].avg_data_transmissions))
        print("\tAvg data Transmissions per cycle: " + str(total_data_transmissions / total_bcasts_for_node))
        node_analysis[node_id].avg_max_queue_sizes = statistics.mean(node_analysis[node_id].max_queue_sizes)
        print("\tAvg Max Data Queue Size per delivered msg: " + str(node_analysis[node_id].avg_max_queue_sizes))
        print("\tAvg Max Data Queue Size per cycle: " + str(queue_size_counter / total_bcasts_for_node))
        print("\tMax Data Queue Size: " + str(max_queue_size))
        node_analysis[node_id].avg_CRC_fails = statistics.mean(node_analysis[node_id].crc_fails)
        print("\tAvg CRC received fails per delivered msg: " + str(node_analysis[node_id].avg_CRC_fails))
        print("\tAvg CRC received fails per cycle: " + str(total_crc_fails / total_bcasts_for_node))
        print("\tTotal Missed Bcasts: " + str(total_missed_bcasts))
        if len(parameters.HARDCODED_NODE_TDMA) > 0:
            print("\tParent Connections (TDMA): ")
        else:
            print("\tParent Connections: ")
        node_analysis[node_id].connection_total = sum(connections)
        node_analysis[node_id].highest_parent_ratio = 0
        for j in range(len(node_assignments)):
            if len(parameters.HARDCODED_NODE_TDMA) > 0:
                print("\t\t" + str(node_assignments[j]) + " (" + str(parameters.HARDCODED_NODE_TDMA[node_assignments[j]]) + ")" + ":\t" + str(connections[j]))
            else:
                print("\t\t" + str(node_assignments[j]) + ":\t" + str(connections[j]))
            if connections[j] > 0:
                parent_connection_ratio = connections[j] / node_analysis[node_id].connection_total
                if parent_connection_ratio > node_analysis[node_id].highest_parent_ratio:
                    node_analysis[node_id].highest_parent_ratio  = parent_connection_ratio
                print("\t\t\tAvg RSSI: " + str(connections_rssi[j] / connections[j]))
                if parameters.PLOT_DISPLAY and len(parameters.HARDCODED_NODE_LOCS) > 0:
                    G.add_edge(node_id, node_assignments[j], weight=connections[j]/parameters.PLOT_LOCS_WEIGHT_SCALAR)
                node_analysis[node_id].connections[node_assignments[j]] = connections[j]
        node_analysis[node_id].avg_rssi = statistics.mean(node_analysis[node_id].rssi)
        print(flush=True)
        
        # Node specific plots
        if parameters.PLOT_DISPLAY and parameters.PLOT_NODE_SPECIFIC_BCASTS:
            """ Bcasts Received Start """
            plot_snode_bcast_nums_padded = []
            if len(plot_snode_bcast_nums) > 0:
                # Since SNODE may have missed GNODE bcasts, fill SNODE array with same value (graph shows horizontal line) if missed
                plot_snode_bcast_nums_padded = []
                n_s_count = 0
                for n_g_idx in range(len(bcast_info)): # Start tracking when SNODE joined the network
                    n_g = bcast_info[n_g_idx].bcast_num
                    n_g_inst = bcast_info[n_g_idx].bcast_inst
                    #print("Debug: looking for " + str(n_g))
                    window_min = max(n_s_count - parameters.PARAM_COUNT_WRAP_SAFETY, 0)
                    window_max = min(n_s_count + parameters.PARAM_COUNT_WRAP_SAFETY, len(plot_snode_bcast_nums) - 1)
                    #print("Debug: Window min idx: " + str(window_min) + " Current idx: " + str(min(n_s_count, window_max)) + " Window max idx: " + str(window_max))
                    #print("Debug: Window min: " + str(plot_snode_bcast_nums[window_min]) + " Current: " + str(plot_snode_bcast_nums[min(n_s_count, window_max)]) + " Window max: " + str(plot_snode_bcast_nums[window_max]))
                    found = -1
                    count_inc = window_min - n_s_count
                    for n_s_idx in range(window_min, window_max):
                        n_s = plot_snode_bcast_nums[n_s_idx]
                        n_s_inst = plot_snode_bcast_insts[n_s_idx]
                        #print("\tDebug: looking at " + str(n_s))
                        count_inc += 1
                        if n_s == n_g and n_s_inst == n_g_inst and not plot_snode_bcast_used[n_s_idx]:
                            found = n_s
                            plot_snode_bcast_used[n_s_idx] = True
                            break
                    if found >= 0:
                        plot_snode_bcast_nums_padded.append(n_s)
                        n_s_count += count_inc
                    else:
                        if len(plot_snode_bcast_nums_padded) > 0:
                            plot_snode_bcast_nums_padded.append(0) # Append last value
                            #print("\tDebug: padding " + str(plot_snode_bcast_nums_padded[-1]))
                        else:
                            plot_snode_bcast_nums_padded.append(0)
                            #print("\tDebug: padding " + str(0))
                            
            figure, axis = plt.subplots(2, sharex=True)
            plt.title("Bcast Num vs Cycle")
            # GNODE
            axis[0].plot([bi.bcast_num for bi in bcast_info])
            axis[0].set_title("GNODE")
            axis[0].set_ylabel("Bcast Num")
            # SNODE
            axis[1].plot(plot_snode_bcast_nums_padded)
            axis[1].set_title("SNODE " + str(node_id))
            axis[1].set_xlabel("Cycle Num")
            axis[1].set_ylabel("Bcast Num")
            plt.show()
            """ Bcasts Received End """

    # Data preparation
    # Build path structurea
    for b_ind in message_paths:
        for b_num in message_paths[b_ind]:
            paths = message_paths[b_ind][b_num]
            search_stack = [0]
            hcount = 0
            search_paths(b_ind, b_num, node_analysis, paths, search_stack, hcount) # Recursively adds in paths to nodes
            # Find and assign children
            for child in paths:
                parent = paths[child]
                if parent.id != 0: # node_analysis does not have data for GNODE (ID 0)
                    if not b_ind in node_analysis[parent.id].cycle_children:
                        node_analysis[parent.id].cycle_children[b_ind] = {}
                    if not b_num in node_analysis[parent.id].cycle_children[b_ind]:
                        node_analysis[parent.id].cycle_children[b_ind][b_num] = []
                    node_analysis[parent.id].cycle_children[b_ind][b_num].append(child)
                    if not child in node_analysis[parent.id].children_counts:
                        node_analysis[parent.id].children_counts[child] = 1
                        node_analysis[parent.id].children_rssi[child] = parent.rssi
                    else:
                        node_analysis[parent.id].children_counts[child] += 1
                        node_analysis[parent.id].children_rssi[child] += parent.rssi
    
    # Average children rssi
    for node in node_analysis.values():
        for child in node.children_counts:
            node.children_rssi[child] /= node.children_counts[child]
        
    # General Analysis
    print("Holistic Analysis")
    print("********************************************************")
    print("********************************************************")
    for node in node_analysis.values():
        print("********************************************************")
        print("Node " + str(node.node_id))
        print("Cycle Hopcount")
        if len(node.hops) > 0:
            print("\tData Points: " + str(len(node.hops)))
            node.hc_mean = statistics.mean(node.hops) # Save for use later
            print("\tMean: " + str(node.hc_mean))
            print("\tStd Dev: " + str(statistics.stdev(node.hops)))
        else:
            print("\tNot enough data")
        print("Cycle Children")
        TDMA_conflicts = []
        if len(node.cycle_children) > 0:
            children = []
            for b_inst in node.cycle_children:
                for b_num in node.cycle_children[b_inst]:
                    children.append(len(node.cycle_children[b_inst][b_num]))
                    if len(parameters.HARDCODED_NODE_TDMA) > 0:
                        cycle_TMDA_slots = set()
                        for child in node.cycle_children[b_inst][b_num]:
                            child_TDMA_slot = parameters.HARDCODED_NODE_TDMA[child]
                            dups = []
                            if not child_TDMA_slot in cycle_TMDA_slots:
                                for c in node.cycle_children[b_inst][b_num]:
                                    c_TDMA_slot = parameters.HARDCODED_NODE_TDMA[c]
                                    if c_TDMA_slot == child_TDMA_slot:
                                        dups.append(c)
                                cycle_TMDA_slots.add(child_TDMA_slot)
                            if len(dups) > 1:
                                TDMA_conflicts.append(dups)
            node.children_mean = statistics.mean(children) # Save for use later
            print("\tMean: " + str(node.children_mean))
            print("\tStd Dev: " + str(statistics.stdev(children)))
            if len(parameters.HARDCODED_NODE_TDMA) > 0:
                print("\tTDMA Conflicts: " + str(len(TDMA_conflicts)))
                print("\t\t" + str(TDMA_conflicts))
        else:
            print("\tNot enough data")
        
        if len(parameters.HARDCODED_NODE_TDMA) > 0:
            print("Children Connections (TDMA)")
        else:
            print("Children Connections")
        for child in node.children_counts:
            if len(parameters.HARDCODED_NODE_TDMA) > 0:
                print("\t" + str(child) + " (" + str(parameters.HARDCODED_NODE_TDMA[child]) + ")" + ":\t" + str(node.children_counts[child]))
            else:
                print("\t" + str(child) + ":\t" + str(node.children_counts[child]))
            print("\t\tAvg RSSI: " + str(node.children_rssi[child]))
    print(flush=True)

    # Plots
    if parameters.PLOT_DISPLAY:
        # Store PDR, prepares map for use below in append plot data
        node_PDR = {}
        node_PDR[0] = 1 # Give GNODE a PDR of 1
        for n_key in node_analysis:
            node_PDR[n_key] = node_analysis[n_key].PDR
    
        # Append node plot data
        node_avg_HC = []
        node_avg_children = []
        node_lifetime_cycles = []
        node_self_PDR = []
        node_weighted_parent_PDR = []
        node_avg_crc_receive_fails = []
        node_avg_data_transmissions = []
        node_avg_max_queue_sizes = []
        node_avg_rssi = []
        node_highest_parent_ratio = []
        node_avg_WTB = []
        for n_key in node_analysis:
            node = node_analysis[n_key]
            if n_key in parameters.HARDCODED_PLOT_EXCLUDE:
                continue # Skip any nodes we mark as "exclude", such as outliers seen from previous runs
            node_self_PDR.append(node.PDR)
            node_avg_HC.append(node.hc_mean)
            node_avg_children.append(node.children_mean)
            node_lifetime_cycles.append(node.cycles)
            node_avg_crc_receive_fails.append(node.avg_CRC_fails)
            node_avg_data_transmissions.append(node.avg_data_transmissions)
            node_avg_max_queue_sizes.append(node.avg_max_queue_sizes)
            node_highest_parent_ratio.append(node.highest_parent_ratio)
            node_avg_rssi.append(node.avg_rssi)
            node_avg_WTB.append(node.avg_wtb)
            total_parents = len(node.connections)
            total_parent_PDR = 0
            total_parent_connections = 0
            for parent in node.connections:
                total_parent_PDR += node_PDR[parent] * node.connections[parent]
                total_parent_connections += node.connections[parent]
            average_parent_PDR = total_parent_PDR / total_parent_connections
            node_weighted_parent_PDR.append(average_parent_PDR)
        
        # Append msg plot data
        msg_parent_rssi = []
        msg_crc_fails = []
        msg_data_transmissions = []
        msg_dropped_cycles = 0
        for msg in msg_analysis.values():
            for bi in msg.cycle_stats:
                for bn in msg.cycle_stats[bi]:
                    cs = msg.cycle_stats[bi][bn] # cycles stats
                    # Only take Cycle Stats with entire stats filled out
                    if cs.parent_rssi != 0 and cs.data_transmissions != -1 and cs.crc_fails != -1:
                        msg_parent_rssi.append(cs.parent_rssi)
                        msg_data_transmissions.append(cs.data_transmissions)
                        msg_crc_fails.append(cs.crc_fails)
                    else:
                        msg_dropped_cycles += 1
        print("Plot Msg total good data: " + str(len(msg_parent_rssi)))
        print("Plot Msg total bad data: " + str(msg_dropped_cycles)) 
           
        # *********** NODE PLOTS ***********
           
        # Self PDR vs Weighted (Connections) Parent PDR
        x_ax = node_weighted_parent_PDR
        y_ax = node_self_PDR
        title = "NODE: Self PDR vs Weighted Parent PDR"
        x_label = "Weighted Parent PDR"
        y_label = "Self PDR"
        for i, node_id in enumerate([node_analysis[n_key].node_id for n_key in node_analysis if not n_key in parameters.HARDCODED_PLOT_EXCLUDE]):
            plt.annotate(node_id, (x_ax[i], y_ax[i]))
        plot_w_lin_reg(x_ax, y_ax, title, x_label, y_label)
    
        # PDR vs Avg HC
        x_ax = node_avg_HC
        y_ax = node_self_PDR
        title = "NODE: PDR vs Avg HC"
        x_label = "Avg HC"
        y_label = "PDR"
        for i, node_id in enumerate([node_analysis[n_key].node_id for n_key in node_analysis if not n_key in parameters.HARDCODED_PLOT_EXCLUDE]):
            plt.annotate(node_id, (x_ax[i], y_ax[i]))
        plot_w_lin_reg(x_ax, y_ax, title, x_label, y_label)
    
        # PDR vs Avg Children
        x_ax = node_avg_children
        y_ax = node_self_PDR
        title = "NODE: PDR vs Avg Children"
        x_label = "Avg Children"
        y_label = "PDR"
        for i, node_id in enumerate([node_analysis[n_key].node_id for n_key in node_analysis if not n_key in parameters.HARDCODED_PLOT_EXCLUDE]):
            plt.annotate(node_id, (x_ax[i], y_ax[i]))
        plot_w_lin_reg(x_ax, y_ax, title, x_label, y_label)
    
        # PDR vs CRC Fails
        x_ax = node_avg_crc_receive_fails
        y_ax = node_self_PDR
        title = "NODE: PDR vs CRC Fails"
        x_label = "CRC Fails"
        y_label = "PDR"
        for i, node_id in enumerate([node_analysis[n_key].node_id for n_key in node_analysis if not n_key in parameters.HARDCODED_PLOT_EXCLUDE]):
            plt.annotate(node_id, (x_ax[i], y_ax[i]))
        plot_w_lin_reg(x_ax, y_ax, title, x_label, y_label)
        
        # PDR vs Avg Data Transmissions
        x_ax = node_avg_data_transmissions
        y_ax = node_self_PDR
        title = "NODE: PDR vs Avg Data Transmissions"
        x_label = "Avg Data Transmissions"
        y_label = "PDR"
        for i, node_id in enumerate([node_analysis[n_key].node_id for n_key in node_analysis if not n_key in parameters.HARDCODED_PLOT_EXCLUDE]):
            plt.annotate(node_id, (x_ax[i], y_ax[i]))
        plot_w_lin_reg(x_ax, y_ax, title, x_label, y_label)
        
        # PDR vs Avg Max Queue Sizes 
        # Naming here is difficult; since queue sizes are reported as the max during a cycle, we take the avg of max queue sizes across received msgs
        x_ax = node_avg_max_queue_sizes
        y_ax = node_self_PDR
        title = "NODE: PDR vs Avg Max Queue Size"
        x_label = "Avg Max Queue Size"
        y_label = "PDR"
        for i, node_id in enumerate([node_analysis[n_key].node_id for n_key in node_analysis if not n_key in parameters.HARDCODED_PLOT_EXCLUDE]):
            plt.annotate(node_id, (x_ax[i], y_ax[i]))
        plot_w_lin_reg(x_ax, y_ax, title, x_label, y_label)
    
        # PDR vs Highest parent ratio, highest parent ratio is the highest connection % a node had to one of its parents
        x_ax = node_highest_parent_ratio
        y_ax = node_self_PDR
        title = "NODE: PDR vs Highest Parent Ratio"
        x_label = "Highest Parent Ratio"
        y_label = "PDR"
        for i, node_id in enumerate([node_analysis[n_key].node_id for n_key in node_analysis if not n_key in parameters.HARDCODED_PLOT_EXCLUDE]):
            plt.annotate(node_id, (x_ax[i], y_ax[i]))
        plot_w_lin_reg(x_ax, y_ax, title, x_label, y_label)
    
        # Avg Max Queue Size vs Avg Data Transmissions
        x_ax = node_avg_data_transmissions
        y_ax = node_avg_max_queue_sizes
        title = "NODE: Avg Max Queue Size vs Avg Data Transmissions"
        x_label = "Avg Data Transmissions"
        y_label = "Avg Max Queue Size"
        for i, node_id in enumerate([node_analysis[n_key].node_id for n_key in node_analysis if not n_key in parameters.HARDCODED_PLOT_EXCLUDE]):
            plt.annotate(node_id, (x_ax[i], y_ax[i]))
        plot_w_lin_reg(x_ax, y_ax, title, x_label, y_label)
    
        # Avg RSSI vs Avg Data Transmissions
        x_ax = node_avg_rssi
        y_ax = node_avg_data_transmissions
        title = "NODE: Avg Data Transmissionsvs vs Avg RSSI"
        x_label = "Avg RSSI"
        y_label = "Avg Data Transmissions"
        for i, node_id in enumerate([node_analysis[n_key].node_id for n_key in node_analysis if not n_key in parameters.HARDCODED_PLOT_EXCLUDE]):
            plt.annotate(node_id, (x_ax[i], y_ax[i]))
        plot_w_lin_reg(x_ax, y_ax, title, x_label, y_label)
    
        # Avg Data Transmissions vs Avg Children
        x_ax = node_avg_children
        y_ax = node_avg_data_transmissions
        title = "NODE: Avg Data Transmissions vs Avg Children"
        x_label = "Avg Children"
        y_label = "Avg Data Transmissions"
        for i, node_id in enumerate([node_analysis[n_key].node_id for n_key in node_analysis if not n_key in parameters.HARDCODED_PLOT_EXCLUDE]):
            plt.annotate(node_id, (x_ax[i], y_ax[i]))
        plot_w_lin_reg(x_ax, y_ax, title, x_label, y_label)
    
        # Avg Data Transmissions vs Avg CRC Fails
        x_ax = node_avg_crc_receive_fails
        y_ax = node_avg_data_transmissions
        title = "NODE: Avg Data Transmissions vs Avg CRC Fails"
        x_label = "Avg CRC Fails"
        y_label = "Avg Data Transmissions"
        for i, node_id in enumerate([node_analysis[n_key].node_id for n_key in node_analysis if not n_key in parameters.HARDCODED_PLOT_EXCLUDE]):
            plt.annotate(node_id, (x_ax[i], y_ax[i]))
        plot_w_lin_reg(x_ax, y_ax, title, x_label, y_label)
    
        # Lifetime (Cycles) vs Avg HC
        x_ax = node_avg_HC
        y_ax = node_lifetime_cycles
        title = "NODE: Lifetime vs Avg HC"
        x_label = "Avg HC"
        y_label = "Lifetime (Cycles)"
        for i, node_id in enumerate([node_analysis[n_key].node_id for n_key in node_analysis if not n_key in parameters.HARDCODED_PLOT_EXCLUDE]):
            plt.annotate(node_id, (x_ax[i], y_ax[i]))
        plot_w_lin_reg(x_ax, y_ax, title, x_label, y_label)
        
        # Lifetime (Cycles) vs Avg Num Children
        x_ax = node_avg_children
        y_ax = node_lifetime_cycles
        title = "NODE: Lifetime vs Avg Children"
        x_label = "Avg Children"
        y_label = "Lifetime (Cycles)"
        for i, node_id in enumerate([node_analysis[n_key].node_id for n_key in node_analysis if not n_key in parameters.HARDCODED_PLOT_EXCLUDE]):
            plt.annotate(node_id, (x_ax[i], y_ax[i]))
        plot_w_lin_reg(x_ax, y_ax, title, x_label, y_label)
        
        # Avg WTB vs Avg Num Children
        x_ax = node_avg_HC
        y_ax = node_avg_WTB
        title = "NODE: Avg WTB vs Avg HC"
        x_label = "Avg HC"
        y_label = "Avg WTB"
        for i, node_id in enumerate([node_analysis[n_key].node_id for n_key in node_analysis if not n_key in parameters.HARDCODED_PLOT_EXCLUDE]):
            plt.annotate(node_id, (x_ax[i], y_ax[i]))
        plot_w_lin_reg(x_ax, y_ax, title, x_label, y_label)

        # *********** MSG PLOTS ***********

        x_ax = msg_parent_rssi
        y_ax = msg_crc_fails
        title = "MSG: CRC Fails vs Parent RSSI"
        x_label = "Parent RSSI"
        y_label = "CRC Fails"
        plot_w_lin_reg(x_ax, y_ax, title, x_label, y_label, False, 0.1)
        
        x_ax = msg_parent_rssi
        y_ax = msg_data_transmissions
        title = "MSG: Data Transmissions vs Parent RSSI"
        x_label = "Parent RSSI"
        y_label = "Data Transmissions"
        plot_w_lin_reg(x_ax, y_ax, title, x_label, y_label, False, 0.1)
        
        x_ax = msg_data_transmissions
        y_ax = msg_crc_fails
        title = "MSG: CRC Fails vs Data Transmissions"
        x_label = "Data Transmissions"
        y_label = "CRC Fails"
        plot_w_lin_reg(x_ax, y_ax, title, x_label, y_label, False, 0.1)

        # Plot HC and number of children connections per cycle per node
        if parameters.PLOT_NODE_SPECIFIC_CONNECTIONS:
            for n_key in node_analysis:
                node = node_analysis[n_key]
                plot_cycles = range(sum(bcast_info_overflow.values()) + len(bcast_info_overflow)) # Add len since values are MAX (not length) and 0 start
                plot_hop_count = []
                plot_children = []
                for bi in bcast_info_overflow:
                    for bn in range(bcast_info_overflow[bi] + 1):
                        if bi in node.cycle_hops and bn in node.cycle_hops[bi]:
                            plot_hop_count.append(node.cycle_hops[bi][bn])
                        else:
                            plot_hop_count.append(0)
                        if bi in node.cycle_children and bn in node.cycle_children[bi]:
                            plot_children.append(len(node.cycle_children[bi][bn]))
                        else:
                            plot_children.append(0)
                figure, axis = plt.subplots(2, sharex=True)
                # GNODE
                axis[0].scatter(plot_cycles, plot_hop_count)
                axis[0].set_title("Node " + str(n_key) + ": Hop Count vs Cycle")
                axis[0].set_ylabel("Hop Count")
                # SNODE
                axis[1].scatter(plot_cycles, plot_children)
                axis[1].set_title("Num Children vs Cycle")
                axis[1].set_xlabel("Cycle")
                axis[1].set_ylabel("Num Children")
                plt.show()
    
        # Plot network with parent-child connections
        if len(parameters.HARDCODED_NODE_LOCS) > 0:
            # nodes
            locs_flipped = {node: (y, x) for (node, (x,y)) in parameters.HARDCODED_NODE_LOCS.items()}
            nx.draw_networkx_nodes(G, locs_flipped, node_size=parameters.NETWORK_DRAW_OPTIONS["node_size"], \
                node_color=parameters.NETWORK_DRAW_OPTIONS["node_color"], edgecolors=parameters.NETWORK_DRAW_OPTIONS["node_edge_color"],
                linewidths=parameters.NETWORK_DRAW_OPTIONS["node_width"])
            # edges
            weighted_edges = [G[u][v]['weight'] for u,v in G.edges()]
            nx.draw_networkx_edges(G, locs_flipped, width=weighted_edges, connectionstyle="angle3")
            # labels
            nx.draw_networkx_labels(G, locs_flipped, font_size=parameters.NETWORK_DRAW_OPTIONS["node_font_size"])

            ax = plt.gca()
            plt.axis("off")
            plt.tight_layout()
            plt.title("Combined Parent Map")
            plt.xlabel("GPS X")
            plt.ylabel("GPS Y")
            plt.show()
            
            # Per Node Plots
            if parameters.PLOT_NODE_SPECIFIC_MAPS:
                for n_key in node_analysis:
                    G.clear()
                    # Show all the nodes
                    for n in node_analysis:
                        G.add_edge(n, n, weight=0)
                    for p in node_analysis[n_key].paths:
                        connections = node_analysis[n_key].connections[p[-2]] # Percentage connections of this path, p[1] is the first parent
                        for node in reversed(range(1, len(p))):
                            G.add_edge(p[node], p[node - 1], weight=connections/parameters.PLOT_LOCS_WEIGHT_SCALAR_SPECIFIC)
                    
                    # nodes
                    nx.draw_networkx_nodes(G, locs_flipped, node_size=parameters.NETWORK_DRAW_OPTIONS["node_size"], \
                        node_color=parameters.NETWORK_DRAW_OPTIONS["node_color"], edgecolors=parameters.NETWORK_DRAW_OPTIONS["node_edge_color"],
                        linewidths=parameters.NETWORK_DRAW_OPTIONS["node_width"])
                    # edges
                    weighted_edges = [G[u][v]['weight'] for u,v in G.edges()]
                    nx.draw_networkx_edges(G, locs_flipped, width=weighted_edges, connectionstyle="angle3")
                    # labels
                    nx.draw_networkx_labels(G, locs_flipped, font_size=parameters.NETWORK_DRAW_OPTIONS["node_font_size"])

                    ax = plt.gca()
                    plt.axis("off")
                    plt.tight_layout()
                    plt.title("Node " + str(n_key) + " Map")
                    plt.xlabel("GPS X")
                    plt.ylabel("GPS Y")
                    plt.show()

        if parameters.PLOT_RSSI_ANALYSIS:
            print("RSSI Analysis # data points: " + str(len(analysis_rssi)))
            plt.scatter(analysis_rssi, analysis_transmissions, alpha=0.1);
            plt.title("Transmissions vs RSSI")
            plt.xlabel("RSSI")
            plt.ylabel("Transmissions")
            plt.show()

if __name__ == "__main__":
    main()